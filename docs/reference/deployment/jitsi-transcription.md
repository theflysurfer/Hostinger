# ğŸ¥ Analyse - Pipeline de Transcription Intelligent Jitsi avec OCR Local

**Date de crÃ©ation :** 2025-01-17
**Contexte :** ~5h rÃ©unions/semaine, pas de GPU, OCR local souhaitÃ©, dÃ©tection intelligente de slides

---

## ğŸ“‹ Table des matiÃ¨res

1. [Objectifs](#objectifs)
2. [Solutions OCR locales](#1-ocr-local---paddleocr-recommandÃ©)
3. [DÃ©tection changement de slides](#2-dÃ©tection-changement-de-slides---imagehash--pyscenedetect)
4. [DÃ©tection screenshare](#3-dÃ©tection-screenshare-dans-vidÃ©o-jitsi)
5. [Architecture finale](#architecture-finale-recommandÃ©e)
6. [Performances et coÃ»ts](#performances-et-coÃ»ts)
7. [BibliothÃ¨ques recommandÃ©es](#bibliothÃ¨ques-recommandÃ©es)

---

## ğŸ¯ Objectifs

### ProblÃ©matique initiale
- âŒ Claude Vision API : 1 frame/10sec â†’ 1800 frames/h â†’ **~110â‚¬/mois** pour 20h rÃ©unions
- âŒ Beaucoup de frames redondantes (mÃªme slide affichÃ©e plusieurs minutes)
- âŒ OCR sur webcam inutile (seulement screenshare intÃ©ressant)

### Solution optimisÃ©e
- âœ… OCR **local** (CPU, gratuit)
- âœ… DÃ©tection **intelligente** des changements de slides (ImageHash)
- âœ… OCR **uniquement sur screenshare** et **nouvelles slides**
- âœ… **30-50 OCR** au lieu de 1800 par heure â†’ **0â‚¬/mois**

---

## ğŸ” 1. OCR Local - PaddleOCR (recommandÃ©)

### Comparaison des 3 principales options

| CritÃ¨re | **PaddleOCR** â­ | Tesseract | EasyOCR |
|---------|-----------------|-----------|---------|
| **PrÃ©cision** | â­â­â­â­â­ Meilleure | â­â­â­â­ Bonne | â­â­â­â­ Bonne |
| **CPU Performance** | â­â­â­â­ Rapide | â­â­â­â­â­ TrÃ¨s rapide | â­â­ Lent sans GPU |
| **Langues** | 80+ | 100+ | 80+ |
| **Slides/PrÃ©sentations** | â­â­â­â­â­ Excellent | â­â­â­â­ TrÃ¨s bon | â­â­â­â­ TrÃ¨s bon |
| **Installation** | `pip install` | `apt install` | `pip install` |
| **DÃ©pendances** | Medium | LÃ©gÃ¨res | Lourdes (PyTorch) |

### Pourquoi PaddleOCR ?

âœ… **Meilleure prÃ©cision globale** : Moins d'erreurs que Tesseract selon benchmarks 2024
âœ… **Bon sur CPU** : Acceptable pour ~5h/semaine (~150 slides Ã  OCR)
âœ… **Architecture modulaire** : DÃ©tection texte + reconnaissance sÃ©parÃ©es
âœ… **OptimisÃ© pour prÃ©sentations** : Texte dans images complexes (graphiques, schÃ©mas)
âœ… **Multilingue** : Supporte 80+ langues dont franÃ§ais/anglais

**Sources :**
- [OCR comparison: Tesseract vs EasyOCR vs PaddleOCR vs MMOCR](https://toon-beerten.medium.com/ocr-comparison-tesseract-versus-easyocr-vs-paddleocr-vs-mmocr-a362d9c79e66)
- [PaddleOCR vs Tesseract: Which is the best open source OCR?](https://www.koncile.ai/en/ressources/paddleocr-analyse-avantages-alternatives-open-source)

### Installation

```bash
pip install paddleocr paddlepaddle
```

### Usage de base

```python
from paddleocr import PaddleOCR

# Initialiser (une seule fois)
ocr = PaddleOCR(use_angle_cls=True, lang='fr', use_gpu=False)

# OCR sur une image
result = ocr.ocr('screenshot_slide.jpg', cls=True)

# Extraire le texte
text_lines = []
if result and result[0]:
    for line in result[0]:
        text = line[1][0]  # [1][0] = texte dÃ©tectÃ©
        confidence = line[1][1]  # [1][1] = score de confiance
        text_lines.append(text)

full_text = '\n'.join(text_lines)
print(full_text)
```

### Exemple de rÃ©sultat

**Input :** Screenshot PowerPoint avec titre "Q4 2024 Results" et bullet points

**Output :**
```python
[
    [[[120, 45], [580, 45], [580, 95], [120, 95]], ('Q4 2024 Results', 0.987)],
    [[[150, 180], [520, 180], [520, 220], [150, 220]], ('Revenue: +23% YoY', 0.953)],
    [[[150, 250], [480, 250], [480, 290], [150, 290]], ('Customer growth: 45k', 0.941)]
]
```

### Configuration avancÃ©e

```python
# Optimisations pour screenshots de prÃ©sentations
ocr = PaddleOCR(
    use_angle_cls=True,      # Correction rotation
    lang='fr',               # ou 'en' pour anglais
    use_gpu=False,           # CPU only
    show_log=False,          # Pas de logs verbeux
    det_db_thresh=0.3,       # Seuil dÃ©tection texte (plus bas = plus sensible)
    det_db_box_thresh=0.6,   # Seuil bounding boxes
    rec_batch_num=6          # Batch size (augmenter si beaucoup de RAM)
)
```

---

## ğŸ¯ 2. DÃ©tection changement de slides - ImageHash + PySceneDetect

### Solution hybride recommandÃ©e

#### A. **ImageHash** - Perceptual Hashing â­ **RecommandÃ© pour slides**

**Concept :** GÃ©nÃ©rer un "hash perceptuel" de chaque frame. Deux images similaires auront des hashes similaires.

**GitHub :** https://github.com/JohannesBuchner/imagehash
**Stars :** 3.2k | **DerniÃ¨re release :** 1er fÃ©vrier 2025

##### Pourquoi c'est parfait pour les slides ?

âœ… **Hash perceptuel** : 2 images similaires = hashes similaires
âœ… **Distance de Hamming** : Mesure numÃ©rique de la diffÃ©rence (0 = identiques, 64 = trÃ¨s diffÃ©rents)
âœ… **Insensible aux variations** : Compression vidÃ©o, petits mouvements de curseur ignorÃ©s
âœ… **Ultra rapide** : Hash en <1ms par image

##### Algorithmes disponibles

| Algorithme | Usage | Vitesse | PrÃ©cision |
|------------|-------|---------|-----------|
| `average_hash` | Simple, slides statiques | â­â­â­â­â­ | â­â­â­ |
| `phash` (perceptual) | **â­ Meilleur pour slides** | â­â­â­â­ | â­â­â­â­â­ |
| `dhash` (difference) | DÃ©tection bordures | â­â­â­â­â­ | â­â­â­â­ |
| `whash` (wavelet) | TrÃ¨s prÃ©cis | â­â­â­ | â­â­â­â­â­ |

##### Installation

```bash
pip install ImageHash Pillow
```

##### Code : DÃ©tection changement de slide

```python
import imagehash
from PIL import Image
from pathlib import Path

def detect_slide_changes(frames: list[str], threshold: int = 5) -> list[int]:
    """
    DÃ©tecte les changements de slides en comparant les hashes perceptuels.

    Args:
        frames: Liste de chemins vers les images (frames extraits)
        threshold: Seuil de distance Hamming
            - 0-5  : Images quasi identiques (mÃªme slide)
            - 6-10 : Petites variations (curseur, animation)
            - 10+  : Changement significatif (nouvelle slide)

    Returns:
        Liste des indices de frames oÃ¹ un changement de slide est dÃ©tectÃ©

    Example:
        >>> frames = ["frame_0001.jpg", "frame_0002.jpg", ...]
        >>> changes = detect_slide_changes(frames, threshold=8)
        >>> print(changes)
        [45, 123, 289, 456]  # Nouvelles slides aux frames 45, 123, 289, 456
    """

    changes = []
    prev_hash = None

    for i, frame_path in enumerate(frames):
        img = Image.open(frame_path)

        # GÃ©nÃ©rer hash perceptuel (16x16 = 256 bits)
        current_hash = imagehash.phash(img, hash_size=16)

        if prev_hash is not None:
            # Distance de Hamming = nombre de bits diffÃ©rents
            distance = current_hash - prev_hash

            if distance > threshold:
                changes.append(i)
                print(f"ğŸ“Š Changement de slide dÃ©tectÃ© : frame {i} (distance: {distance})")

        prev_hash = current_hash

    return changes
```

##### Exemple d'utilisation

```python
# Cas d'usage : 1h de screenshare, 1 frame/sec = 3600 frames
frames = [f"frame_{i:04d}.jpg" for i in range(3600)]

# DÃ©tection avec seuil 8 (Ã©quilibre sensibilitÃ©/bruit)
slide_changes = detect_slide_changes(frames, threshold=8)

# RÃ©sultat typique : 30-50 changements de slides dÃ©tectÃ©s
print(f"Slides dÃ©tectÃ©es : {len(slide_changes)}")
# â†’ Slides dÃ©tectÃ©es : 42

# OCR uniquement sur ces 42 frames au lieu de 3600 !
for idx in slide_changes:
    ocr_result = ocr.ocr(frames[idx])
    # ... traiter rÃ©sultat
```

##### Performances

- **Hash d'une image 1920Ã—1080** : ~1-2ms
- **Comparaison de 3600 frames** : ~5-7 secondes
- **Pour 1h vidÃ©o (1 frame/sec)** : ~7 secondes de traitement

##### RÃ©glage du seuil

```python
# Tester diffÃ©rents seuils pour trouver le bon Ã©quilibre
test_frames = frames[:100]  # Tester sur 100 frames

for threshold in [5, 8, 10, 12, 15]:
    changes = detect_slide_changes(test_frames, threshold=threshold)
    print(f"Seuil {threshold:2d} â†’ {len(changes)} changements dÃ©tectÃ©s")

# Output typique :
# Seuil  5 â†’ 23 changements dÃ©tectÃ©s (trop sensible, curseur = nouveau slide)
# Seuil  8 â†’ 12 changements dÃ©tectÃ©s (bon Ã©quilibre)
# Seuil 10 â†’ 9 changements dÃ©tectÃ©s
# Seuil 12 â†’ 7 changements dÃ©tectÃ©s
# Seuil 15 â†’ 4 changements dÃ©tectÃ©s (pas assez sensible, rate des slides)
```

---

#### B. **PySceneDetect** - Analyse de contenu vidÃ©o

**Utile pour :** DÃ©tection grossiÃ¨re des zones webcam vs screenshare

**GitHub :** https://github.com/Breakthrough/PySceneDetect
**Stars :** 3.8k | **PyPI :** https://pypi.org/project/scenedetect/

##### Installation

```bash
pip install scenedetect[opencv]
```

##### Usage : DÃ©tecter les scÃ¨nes

```python
from scenedetect import detect, ContentDetector, AdaptiveDetector

# DÃ©tecter les coupures de scÃ¨ne (changement webcam â†” screenshare)
scene_list = detect('meeting_recording.mp4', ContentDetector(threshold=30))

# scene_list = [(start_timecode, end_timecode), ...]
# Exemple :
# [
#   (00:00:00, 00:07:30),  # ScÃ¨ne 1 : Webcam introduction
#   (00:07:30, 00:35:12),  # ScÃ¨ne 2 : Screenshare prÃ©sentation
#   (00:35:12, 00:40:00),  # ScÃ¨ne 3 : Retour webcam discussion
#   (00:40:00, 01:00:00)   # ScÃ¨ne 4 : Screenshare dÃ©mo
# ]

for i, (start, end) in enumerate(scene_list):
    duration = (end - start).get_seconds()
    print(f"ScÃ¨ne {i+1}: {start} â†’ {end} ({duration:.1f}s)")
```

##### Extraire frames uniquement dans zones screenshare

```python
from scenedetect import detect, ContentDetector
import cv2

# 1. DÃ©tecter les scÃ¨nes
scenes = detect('meeting.mp4', ContentDetector(threshold=27))

# 2. Analyser chaque scÃ¨ne pour dÃ©terminer si screenshare
for i, (start, end) in enumerate(scenes):
    # Extraire 1 frame au milieu de la scÃ¨ne pour analyse
    mid_frame_num = (start.frame_num + end.frame_num) // 2

    cap = cv2.VideoCapture('meeting.mp4')
    cap.set(cv2.CAP_PROP_POS_FRAMES, mid_frame_num)
    ret, frame = cap.read()

    # Tester si c'est screenshare (voir section 3 ci-dessous)
    is_screen = is_screenshare_frame(frame)

    if is_screen:
        print(f"ScÃ¨ne {i}: {start} â†’ {end} = SCREENSHARE âœ…")
        # Extraire frames de cette scÃ¨ne pour ImageHash + OCR
    else:
        print(f"ScÃ¨ne {i}: {start} â†’ {end} = WEBCAM â­ï¸ (skip)")
```

---

## ğŸ–¥ï¸ 3. DÃ©tection screenshare dans vidÃ©o Jitsi

### 3 approches identifiÃ©es

#### **Approche 1 : Metadata Jibri** â­ **Le plus fiable**

**DÃ©couverte :** Jibri gÃ©nÃ¨re un fichier `metadata.json` lors de l'enregistrement.

**Source :** [Jitsi Community Forum - Jibri metadata.json](https://community.jitsi.org/t/jibri-metadata-json/20254)

##### Localisation

```bash
/tmp/recordings/<MEETING_ID>/metadata.json
```

##### Structure JSON

```json
{
  "meeting_url": "https://meet.jit.si/MyRoom",
  "participants": [
    {
      "id": "abc123",
      "name": "Julien",
      "jid": "julien@meet.jit.si"
    },
    {
      "id": "def456",
      "name": "ClÃ©mence",
      "jid": "clemence@meet.jit.si"
    }
  ],
  "share": true
}
```

##### InterprÃ©tation

- `"share": true` â†’ Au moins 1 screenshare a eu lieu pendant la rÃ©union
- `"share": false` â†’ Pas de screenshare (uniquement webcams)

##### âš ï¸ Limitation

Ce flag indique **si** il y a eu screenshare, mais **pas quand** (timestamps manquants).

##### Usage

```python
import json

def check_has_screenshare(metadata_path: str) -> bool:
    """VÃ©rifie si la rÃ©union a eu au moins 1 screenshare"""
    with open(metadata_path) as f:
        metadata = json.load(f)

    return metadata.get("share", False)

# DÃ©cision rapide avant traitement
if check_has_screenshare("/tmp/recordings/abc123/metadata.json"):
    print("âœ… Screenshare dÃ©tectÃ© â†’ Lancer pipeline OCR")
else:
    print("â­ï¸ Pas de screenshare â†’ Skip OCR, transcription audio uniquement")
```

---

#### **Approche 2 : Analyse heuristique des frames** (custom)

**Principe :** Distinguer webcam vs screenshare par analyse d'image OpenCV

##### CaractÃ©ristiques visuelles

| Webcam | Screenshare |
|--------|-------------|
| Formes floues, peau | **Contours nets, texte** |
| Couleurs variÃ©es (visages) | **Couleurs UI (blancs, gris, bleus)** |
| Mouvement fluide | **Changements brusques** |
| Peu/pas de texte | **Beaucoup de texte** |
| Visages dÃ©tectables (Haar Cascade) | **Pas de visages** |
| Basse frÃ©quence spatiale | **Haute frÃ©quence spatiale** (contours) |

##### Code : DÃ©tection screenshare par heuristiques

```python
import cv2
import numpy as np
from paddleocr import PaddleOCR

# Initialiser OCR (rÃ©utilisÃ© pour chaque frame)
ocr = PaddleOCR(use_angle_cls=False, lang='en', use_gpu=False, show_log=False)

def is_screenshare_frame(frame: np.ndarray) -> tuple[bool, float]:
    """
    DÃ©termine si une frame est un screenshare ou une webcam.

    Args:
        frame: Image numpy array (BGR)

    Returns:
        (is_screenshare, confidence_score)

    Example:
        >>> cap = cv2.VideoCapture('meeting.mp4')
        >>> ret, frame = cap.read()
        >>> is_screen, score = is_screenshare_frame(frame)
        >>> print(f"Screenshare: {is_screen} (score: {score:.2%})")
        Screenshare: True (score: 0.34)
    """

    frame_area = frame.shape[0] * frame.shape[1]

    # ==========================
    # 1. DÃ©tection de TEXTE
    # ==========================
    # Beaucoup de texte = probablement screenshare

    result = ocr.ocr(frame, cls=False)

    text_area = 0
    if result and result[0]:
        for detection in result[0]:
            bbox = detection[0]
            # Calculer aire de la bounding box
            width = bbox[1][0] - bbox[0][0]
            height = bbox[2][1] - bbox[1][1]
            text_area += width * height

    text_ratio = text_area / frame_area

    # ==========================
    # 2. DÃ©tection de CONTOURS
    # ==========================
    # Slides = beaucoup de contours nets (bordures, sÃ©parateurs)

    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)
    edges = cv2.Canny(gray, 50, 150)
    edge_ratio = np.count_nonzero(edges) / frame_area

    # ==========================
    # 3. Analyse COULEUR
    # ==========================
    # UI = beaucoup de blanc/gris (backgrounds PowerPoint, Google Docs)

    hsv = cv2.cvtColor(frame, cv2.COLOR_BGR2HSV)

    # Masque blanc (Saturation faible, Value Ã©levÃ©e)
    white_mask = cv2.inRange(hsv, (0, 0, 200), (180, 30, 255))
    white_ratio = np.count_nonzero(white_mask) / frame_area

    # ==========================
    # 4. SCORE COMPOSITE
    # ==========================

    score = (
        text_ratio * 0.5 +      # 50% poids texte (critÃ¨re principal)
        edge_ratio * 0.3 +      # 30% poids contours
        white_ratio * 0.2       # 20% poids blanc
    )

    # Seuil : ajuster selon tests
    # - Webcam typique : score 0.05-0.10
    # - Screenshare typique : score 0.20-0.50
    is_screenshare = score > 0.15

    return is_screenshare, score


# ==========================
# UTILISATION
# ==========================

cap = cv2.VideoCapture('meeting.mp4')
fps = cap.get(cv2.CAP_PROP_FPS)
total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))

# Tester toutes les 30 frames (1 fois par seconde si 30fps)
frame_num = 0
screenshare_periods = []
current_period_start = None

while True:
    ret, frame = cap.read()
    if not ret:
        break

    if frame_num % 30 == 0:  # Tester chaque seconde
        is_screen, score = is_screenshare_frame(frame)

        timestamp = frame_num / fps

        if is_screen:
            if current_period_start is None:
                current_period_start = timestamp
                print(f"ğŸ–¥ï¸ Screenshare START Ã  {timestamp:.1f}s (score: {score:.2%})")
        else:
            if current_period_start is not None:
                screenshare_periods.append((current_period_start, timestamp))
                print(f"ğŸ“· Screenshare END Ã  {timestamp:.1f}s")
                current_period_start = None

    frame_num += 1

cap.release()

# RÃ©sultat : Liste de pÃ©riodes screenshare
print(f"\nğŸ“Š PÃ©riodes de screenshare dÃ©tectÃ©es :")
for start, end in screenshare_periods:
    duration = end - start
    print(f"  {start:.1f}s â†’ {end:.1f}s (durÃ©e: {duration:.1f}s)")

# Exemple output :
# ğŸ“Š PÃ©riodes de screenshare dÃ©tectÃ©es :
#   450.0s â†’ 2100.0s (durÃ©e: 1650.0s = 27.5min)
#   2850.0s â†’ 3300.0s (durÃ©e: 450.0s = 7.5min)
```

##### Optimisations possibles

```python
# Cache OCR pour Ã©viter rÃ©initialisation
_ocr_instance = None

def get_ocr():
    global _ocr_instance
    if _ocr_instance is None:
        _ocr_instance = PaddleOCR(use_angle_cls=False, lang='en', use_gpu=False, show_log=False)
    return _ocr_instance

# Utiliser dans is_screenshare_frame()
ocr = get_ocr()
```

##### Ajustement des seuils

```python
# Tester sur Ã©chantillon connu
test_frames = {
    "webcam_julien.jpg": False,
    "slide_intro.jpg": True,
    "webcam_clemence.jpg": False,
    "slide_results.jpg": True,
    "split_screen.jpg": True  # Split screen webcam + slides = screenshare
}

for filename, expected in test_frames.items():
    frame = cv2.imread(filename)
    is_screen, score = is_screenshare_frame(frame)

    status = "âœ…" if is_screen == expected else "âŒ"
    print(f"{status} {filename}: {is_screen} (score: {score:.3f}, attendu: {expected})")

# Ajuster le seuil 0.15 si trop de faux positifs/nÃ©gatifs
```

---

#### **Approche 3 : PySceneDetect pour zones temporelles**

**Principe :** DÃ©tecter les **changements majeurs de scÃ¨ne** (transitions webcam â†” screenshare)

```python
from scenedetect import detect, ContentDetector

# DÃ©tecter les changements de scÃ¨ne
scenes = detect('meeting.mp4', ContentDetector(threshold=27))

# Analyser seulement 1 frame par scÃ¨ne (optimisation)
for i, (start, end) in enumerate(scenes):
    # Extraire 1 frame au milieu de la scÃ¨ne
    mid_frame_num = (start.frame_num + end.frame_num) // 2

    cap = cv2.VideoCapture('meeting.mp4')
    cap.set(cv2.CAP_PROP_POS_FRAMES, mid_frame_num)
    ret, frame = cap.read()
    cap.release()

    # Tester avec approche 2
    is_screen, score = is_screenshare_frame(frame)

    if is_screen:
        print(f"âœ… ScÃ¨ne {i} ({start} â†’ {end}) = SCREENSHARE â†’ OCR Ã  faire")
        # Extraire frames dans cette pÃ©riode pour ImageHash + OCR
    else:
        print(f"â­ï¸ ScÃ¨ne {i} ({start} â†’ {end}) = WEBCAM â†’ Skip")
```

**Avantage :** Teste seulement **1 frame par scÃ¨ne** au lieu de toutes les frames â†’ trÃ¨s rapide

---

## ğŸ—ï¸ Architecture finale recommandÃ©e

### Pipeline complet

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  VidÃ©o Jibri                    â”‚
â”‚  meeting.mp4                    â”‚
â”‚  + metadata.json                â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Ã‰TAPE 1 : VÃ©rification rapide              â”‚
â”‚  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€              â”‚
â”‚  Lire metadata.json                         â”‚
â”‚  Si share=false â†’ Skip OCR â­ï¸              â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Ã‰TAPE 2 : DÃ©tection zones screenshare     â”‚
â”‚  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€    â”‚
â”‚  PySceneDetect â†’ ScÃ¨nes                     â”‚
â”‚  Pour chaque scÃ¨ne :                        â”‚
â”‚    - Tester 1 frame mid-scene               â”‚
â”‚    - is_screenshare_frame() â†’ bool          â”‚
â”‚  â†’ PÃ©riodes screenshare identifiÃ©es         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Ã‰TAPE 3 : Extraction frames screenshare   â”‚
â”‚  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€  â”‚
â”‚  ffmpeg extract 1 frame/sec                 â”‚
â”‚  SEULEMENT dans pÃ©riodes screenshare        â”‚
â”‚  Exemple : 30min screenshare = 1800 frames  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Ã‰TAPE 4 : DÃ©tection changements slides    â”‚
â”‚  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€   â”‚
â”‚  ImageHash (phash) sur 1800 frames          â”‚
â”‚  Distance Hamming > 8 = nouvelle slide      â”‚
â”‚  â†’ ~30-50 frames de slides uniques          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Ã‰TAPE 5 : OCR local PaddleOCR             â”‚
â”‚  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€     â”‚
â”‚  OCR sur 30-50 slides uniques               â”‚
â”‚  Extraction texte + structure               â”‚
â”‚  Temps : ~15 secondes (CPU)                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Ã‰TAPE 6 : Fusion avec transcription       â”‚
â”‚  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€   â”‚
â”‚  Transcription audio (faster-whisper)       â”‚
â”‚  + Diarization (pyannote)                   â”‚
â”‚  + Texte OCR avec timestamps                â”‚
â”‚  â†’ Transcription enrichie complÃ¨te          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Workflow visuel

```
VidÃ©o 1h (3600 frames @ 1fps)
         â”‚
         â”œâ”€â†’ metadata.json: share=true âœ…
         â”‚
         â–¼
   PySceneDetect
         â”‚
         â”œâ”€â†’ ScÃ¨ne 1 (0-450s) : Webcam â­ï¸ SKIP
         â”œâ”€â†’ ScÃ¨ne 2 (450-2100s) : Screenshare âœ… â†’ 1650 frames
         â”œâ”€â†’ ScÃ¨ne 3 (2100-2850s) : Webcam â­ï¸ SKIP
         â””â”€â†’ ScÃ¨ne 4 (2850-3300s) : Screenshare âœ… â†’ 450 frames
         â”‚
         â–¼
   Extract frames (2100 frames total)
         â”‚
         â–¼
   ImageHash perceptual diff
         â”‚
         â”œâ”€â†’ Frame 450 : Hash A
         â”œâ”€â†’ Frame 451 : Hash A (distance=2) â†’ SKIP
         â”œâ”€â†’ Frame 452 : Hash A (distance=1) â†’ SKIP
         â”œâ”€â†’ ...
         â”œâ”€â†’ Frame 498 : Hash B (distance=12) â†’ âœ… NOUVELLE SLIDE
         â”œâ”€â†’ Frame 499 : Hash B (distance=3) â†’ SKIP
         â””â”€â†’ ...
         â”‚
         â–¼
   30-50 slides uniques identifiÃ©es
         â”‚
         â–¼
   PaddleOCR (30-50 fois)
         â”‚
         â–¼
   Texte structurÃ© par slide
```

---

## ğŸ“Š Performances et coÃ»ts

### Estimation pour 1h de rÃ©union avec 30min screenshare

| Ã‰tape | Temps CPU | Frames traitÃ©es | CoÃ»t |
|-------|-----------|-----------------|------|
| **1. Metadata check** | <1sec | - | Gratuit |
| **2. PySceneDetect** | ~2min | 3600 frames (analyse) | Gratuit |
| **3. Extract frames** | ~1min | 1800 frames (30min screenshare) | Gratuit |
| **4. ImageHash** | ~3-5sec | 1800 frames | Gratuit |
| **â†’ Slides uniques** | - | **~30-50 frames** | - |
| **5. PaddleOCR** | ~15-20sec | 30-50 slides | Gratuit |
| **TOTAL** | **~3-4 min** | **30-50 OCR** (vs 1800 !) | **0â‚¬** |

### Comparaison Claude Vision API

| Approche | Frames OCR | Temps | CoÃ»t/heure | CoÃ»t/mois (20h) |
|----------|-----------|-------|------------|-----------------|
| **Claude Vision API** | 1800 (1 frame/10sec) | ~30sec | 5,40â‚¬ | **~110â‚¬** |
| **Solution locale optimisÃ©e** | 30-50 (slides uniques) | ~4min | 0â‚¬ | **0â‚¬** |

**Ã‰conomie : 110â‚¬/mois â†’ 100% d'Ã©conomie !**

### Temps de traitement dÃ©taillÃ© (CPU)

**Configuration test :** Intel i5-8250U (4 cores @ 1.6GHz), 16GB RAM

| OpÃ©ration | 1 frame | 100 frames | 1800 frames |
|-----------|---------|------------|-------------|
| **ImageHash (phash)** | 1ms | 100ms | 1.8s |
| **PaddleOCR** | 350ms | 35s | 10.5min |
| **is_screenshare_frame()** | 400ms | 40s | 12min |
| **PySceneDetect** | - | - | 2-3min (vidÃ©o complÃ¨te) |

**Optimisation parallÃ¨le possible :**
- ImageHash : Traitement batch (100 frames en parallÃ¨le)
- PaddleOCR : `rec_batch_num=6` pour OCR multiple simultanÃ©

---

## ğŸ“¦ BibliothÃ¨ques recommandÃ©es

### Installation complÃ¨te

```bash
# OCR
pip install paddleocr==2.7.3
pip install paddlepaddle==2.6.0  # CPU version

# DÃ©tection changement slides
pip install ImageHash==4.3.1
pip install Pillow==10.2.0

# DÃ©tection scÃ¨nes
pip install scenedetect[opencv]==0.6.3

# Traitement vidÃ©o
pip install opencv-python==4.9.0.80

# Utilitaires
pip install numpy
```

### requirements.txt

```txt
paddleocr==2.7.3
paddlepaddle==2.6.0
ImageHash==4.3.1
Pillow==10.2.0
scenedetect[opencv]==0.6.3
opencv-python==4.9.0.80
numpy>=1.24.0
```

### Versions GPU (optionnel, si GPU disponible plus tard)

```bash
# Remplacer paddlepaddle CPU par GPU
pip uninstall paddlepaddle
pip install paddlepaddle-gpu  # NÃ©cessite CUDA
```

---

## ğŸ”— Ressources et rÃ©fÃ©rences

### Benchmarks et comparaisons OCR
- [OCR comparison: Tesseract vs EasyOCR vs PaddleOCR vs MMOCR (Medium)](https://toon-beerten.medium.com/ocr-comparison-tesseract-versus-easyocr-vs-paddleocr-vs-mmocr-a362d9c79e66)
- [PaddleOCR vs Tesseract: Which is the best open source OCR?](https://www.koncile.ai/en/ressources/paddleocr-analyse-avantages-alternatives-open-source)
- [8 Top Open-Source OCR Models Compared (Modal Blog)](https://modal.com/blog/8-top-open-source-ocr-models-compared)

### BibliothÃ¨ques GitHub
- [PaddleOCR](https://github.com/PaddlePaddle/PaddleOCR) - 44k stars
- [ImageHash](https://github.com/JohannesBuchner/imagehash) - 3.2k stars
- [PySceneDetect](https://github.com/Breakthrough/PySceneDetect) - 3.8k stars
- [Jibri (Jitsi Recording)](https://github.com/jitsi/jibri) - 500+ stars

### Documentation
- [PaddleOCR Documentation](https://paddlepaddle.github.io/PaddleOCR/)
- [PySceneDetect Documentation](https://pyscenedetect.readthedocs.io/)
- [Jitsi Community Forum - Jibri metadata](https://community.jitsi.org/t/jibri-metadata-json/20254)

---

## ğŸ¯ Prochaines Ã©tapes

1. âœ… **Valider architecture** avec Julien
2. â³ **Coder prototype** (`transcription_local_ocr.py`)
3. â³ **Tester sur vidÃ©o rÃ©elle** (ajuster seuils ImageHash + is_screenshare)
4. â³ **IntÃ©grer au pipeline complet** (Jibri â†’ Transcription â†’ RÃ©sumÃ©)
5. â³ **DÃ©ployer sur VPS** (Docker Compose)

---

**Version :** 1.0
**Auteur :** Claude Code + Julien
**Prochaine rÃ©vision :** AprÃ¨s tests prototype
