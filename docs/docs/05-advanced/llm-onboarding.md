# Guide d'Entr√©e pour LLM - srv759970.hstgr.cloud

**Version:** 1.0
**Derni√®re mise √† jour:** 2025-10-27
**Public cible:** Assistants IA (Claude, GPT, etc.) d√©couvrant le serveur pour la premi√®re fois

---

## üéØ Objectif de ce Document

Ce guide permet √† un LLM de comprendre rapidement l'infrastructure srv759970, ses services, et de r√©pondre efficacement aux questions de l'administrateur (Julien).

---

## üìã Vue d'Ensemble - √Ä Lire en Premier

### Identit√© du Serveur

- **Nom:** srv759970.hstgr.cloud
- **IP:** 69.62.108.82
- **H√©bergeur:** Hostinger VPS
- **OS:** Ubuntu 24.04 LTS
- **Admin:** Julien Fernandez (propri√©taire unique)
- **Acc√®s SSH:** `ssh root@69.62.108.82`

### Type d'Infrastructure

**Serveur d'applications multi-services** h√©bergeant:
- 40+ conteneurs Docker
- 30+ services web/APIs
- Stack compl√®te IA (transcription, TTS, LLM, RAG)
- Sites WordPress et applications m√©tier
- Infrastructure de monitoring et collaboration

### Architecture Globale

```mermaid
graph TB
    subgraph Internet
        Users[Utilisateurs]
        API_Consumers[D√©veloppeurs API]
    end

    subgraph "Nginx Reverse Proxy (Port 443/80)"
        Nginx[Nginx + SSL/TLS]
        BasicAuth[Basic Auth Layer]
    end

    subgraph "Docker Autostart System (Port 8890)"
        AutoStart[Auto-Start Proxy<br/>22 services]
    end

    subgraph "Core Services - Always Running"
        Dashy[Dashy Portal :4000]
        MkDocs[MkDocs Docs :8005]
        Redis_Queue[Redis Queue :6379]
        Monitoring[Grafana+Prometheus+Loki]
    end

    subgraph "AI Services - Auto-Start"
        WhisperX[WhisperX :8002]
        FasterWhisper[Faster-Whisper Queue :8003]
        Ollama[Ollama LLM :11434]
        RAGFlow[RAGFlow :9500]
        Tika[Tika :9998]
    end

    subgraph "Web Services - Auto-Start"
        WordPress[WordPress Sites x4]
        Nextcloud[Nextcloud :8505]
        Jitsi[Jitsi Meet :8510]
        RocketChat[Rocket.Chat :3002]
    end

    subgraph "Document Management - Auto-Start"
        Paperless[Paperless-ngx :8000]
        PaperlessAI[Paperless AI]
    end

    Users --> Nginx
    API_Consumers --> Nginx
    Nginx --> BasicAuth
    BasicAuth --> Dashy
    BasicAuth --> MkDocs
    BasicAuth --> AutoStart

    AutoStart -.Auto-Wake.-> WhisperX
    AutoStart -.Auto-Wake.-> FasterWhisper
    AutoStart -.Auto-Wake.-> WordPress
    AutoStart -.Auto-Wake.-> Nextcloud

    WhisperX --> Redis_Queue
    FasterWhisper --> Redis_Queue

    Monitoring --> Redis_Queue
    Monitoring --> WhisperX
    Monitoring --> FasterWhisper
```

---

## üîë Concepts Cl√©s √† Comprendre

### 1. Syst√®me Auto-Start/Stop (IMPORTANT!)

**Localisation:** `/opt/docker-autostart/`
**Fonction:** √âconomise la RAM en arr√™tant les services inactifs apr√®s 15 minutes

**Services concern√©s:** 22 services sur 30+
**Port proxy:** 8890
**M√©canisme:**
1. Nginx re√ßoit requ√™te ‚Üí redirige vers port 8890
2. Auto-start proxy d√©tecte service arr√™t√© ‚Üí le d√©marre
3. Affiche page de chargement pendant 30-180s
4. Redirige vers service actif
5. Apr√®s 15 min d'inactivit√© ‚Üí arr√™te le service

**Services EXCLUS (toujours actifs):**
- Dashy (portail principal)
- MkDocs (documentation)
- Redis Queue (d√©pendance critique)
- Nginx (reverse proxy)
- Monitoring stack

### 2. Architecture d'Authentification

**M√©thode:** HTTP Basic Authentication via Nginx
**Credentials:** `julien:DevAccess2025`
**Fichier:** `/etc/nginx/.htpasswd`
**Snippet:** `/etc/nginx/snippets/basic-auth.conf`

**Pourquoi Basic Auth et pas OAuth?**
‚Üí Voir [Analyse Auth Strategy](analysis/auth-strategy-oauth-vs-basic.md)
**TL;DR:** Simplicit√© (0MB RAM, 5min setup) vs OAuth (300MB RAM, 4h setup) pour un usage solo

### 3. Organisation Docker

**Principe:** 1 service = 1 dossier `/opt/<service>/` avec `docker-compose.yml`

**Exemples:**
- `/opt/whisperx/` ‚Üí WhisperX API
- `/opt/dashy/` ‚Üí Dashy portal
- `/opt/wordpress-clemence/` ‚Üí Site Cl√©mence

**Commandes communes:**
```bash
cd /opt/<service>
docker-compose up -d      # D√©marrer
docker-compose logs -f    # Voir logs
docker-compose restart    # Red√©marrer
docker-compose down       # Arr√™ter
```

### 4. Stack de Transcription (AI Core)

**Architecture partag√©e:**
```
Redis Partag√© (rq-queue-redis:6379)
‚îú‚îÄ‚îÄ DB 0: Queue "transcription" (WhisperX)
‚îî‚îÄ‚îÄ DB 1: Queue "faster-whisper-transcription"

WhisperX Worker ‚Üí WhisperX API (:8002)
Faster-Whisper Worker ‚Üí Faster-Whisper Queue API (:8003)
```

**Monitoring:**
- Grafana: https://monitoring.srv759970.hstgr.cloud
- RQ Dashboard: https://whisperx-dashboard.srv759970.hstgr.cloud
- Prometheus: http://srv759970.hstgr.cloud:9090

---

## üìö Structure de la Documentation

### Navigation Rapide

| Section | Contenu | Quand l'utiliser |
|---------|---------|------------------|
| **[index.md](index.md)** | Vue d'ensemble, liens rapides | Point d'entr√©e, d√©couverte |
| **[Services/](services/)** | Fiches techniques par service | "Comment utiliser X?" |
| **[Infrastructure/](infrastructure/)** | Docker, Nginx, S√©curit√© | "Comment √ßa fonctionne?" |
| **[Guides/](guides/)** | Tutoriels d√©ploiement | "Comment faire Y?" |
| **[Reference/](reference/)** | Commandes, snippets | "Quelle commande pour Z?" |
| **[Changelog/](changelog/)** | Historique modifications | "Qu'est-ce qui a chang√©?" |
| **[Analysis/](analysis/)** | D√©cisions techniques | "Pourquoi ce choix?" |

### Pages Critiques √† Conna√Ætre

1. **[SERVER_STATUS.md](SERVER_STATUS.md)** - √âtat serveur en temps r√©el (auto-g√©n√©r√©)
2. **[SERVICES_STATUS.md](SERVICES_STATUS.md)** - Statut de tous les services (auto-g√©n√©r√©)
3. **[EMERGENCY_RUNBOOK.md](EMERGENCY_RUNBOOK.md)** - Proc√©dures d'urgence
4. **[guides/getting-started/vps-initial-setup.md](guides/getting-started/vps-initial-setup.md)** - Setup complet du serveur

---

## üöÄ Services Principaux - R√©f√©rence Rapide

### Intelligence Artificielle

| Service | URL | Port | Description | Auto-Start |
|---------|-----|------|-------------|------------|
| **WhisperX** | https://whisperx.srv759970.hstgr.cloud | 8002 | Transcription + diarization | ‚úÖ |
| **Faster-Whisper Queue** | https://faster-whisper.srv759970.hstgr.cloud | 8003 | Transcription async avec RQ | ‚úÖ |
| **Ollama** | http://srv759970.hstgr.cloud:11434 | 11434 | Inf√©rence LLM locale | ‚ùå |
| **RAGFlow** | https://ragflow.srv759970.hstgr.cloud | 9500 | Plateforme RAG compl√®te | ‚úÖ |
| **Tika** | http://srv759970.hstgr.cloud:9998 | 9998 | Parsing documents | ‚úÖ |
| **NeuTTS** | https://neutts-api.srv759970.hstgr.cloud | - | Synth√®se vocale | ‚úÖ |

### Collaboration

| Service | URL | Port | Description | Auto-Start |
|---------|-----|------|-------------|------------|
| **Nextcloud** | https://nextcloud.srv759970.hstgr.cloud | 8505 | Stockage cloud | ‚úÖ |
| **Rocket.Chat** | https://chat.srv759970.hstgr.cloud | 3002 | Messagerie √©quipe | ‚úÖ |
| **Jitsi Meet** | https://meet.srv759970.hstgr.cloud | 8510 | Visioconf√©rence | ‚úÖ |

### Infrastructure

| Service | URL | Port | Description | Auto-Start |
|---------|-----|------|-------------|------------|
| **Dashy** | https://dashy.srv759970.hstgr.cloud | 4000 | Portail services | ‚ùå Always ON |
| **MkDocs** | https://docs.srv759970.hstgr.cloud | 8005 | Documentation | ‚ùå Always ON |
| **Grafana** | https://monitoring.srv759970.hstgr.cloud | 3001 | Monitoring | ‚ùå Always ON |
| **Dozzle** | https://dozzle.srv759970.hstgr.cloud | 8888 | Logs Docker | ‚ùå Always ON |
| **Portainer** | https://portainer.srv759970.hstgr.cloud | 9000 | Gestion Docker | ‚ùå Always ON |

---

## üîç Patterns de Questions Fr√©quentes

### "Comment red√©marrer le service X?"

```bash
ssh root@69.62.108.82
cd /opt/<service-name>
docker-compose restart
```

**Exemples concrets:**
- WhisperX: `cd /opt/whisperx && docker-compose restart`
- Dashy: `cd /opt/dashy && docker-compose restart`
- Nextcloud: `cd /opt/nextcloud && docker-compose restart`

### "Le service X ne r√©pond pas"

**Checklist de diagnostic:**
1. V√©rifier si auto-start (attendre 30-180s de chargement)
2. V√©rifier logs: `docker logs <container-name> --tail 50`
3. V√©rifier statut: `docker ps | grep <service>`
4. V√©rifier Nginx: `nginx -t && systemctl status nginx`
5. Voir [EMERGENCY_RUNBOOK.md](EMERGENCY_RUNBOOK.md)

### "Comment ajouter un nouveau service?"

**Template standard:**
1. Cr√©er `/opt/<service>/docker-compose.yml`
2. Configurer Nginx dans `/etc/nginx/sites-available/<service>`
3. Activer: `ln -s /etc/nginx/sites-available/<service> /etc/nginx/sites-enabled/`
4. Tester: `nginx -t`
5. Recharger: `systemctl reload nginx`
6. (Optionnel) Ajouter √† auto-start dans `/opt/docker-autostart/config.json`

‚Üí Voir [guides/deployment/](guides/deployment/) pour d√©tails

### "Quelle est la diff√©rence entre WhisperX et Faster-Whisper Queue?"

| Crit√®re | WhisperX | Faster-Whisper Queue |
|---------|----------|----------------------|
| **Mod√®le** | large-v2 | medium |
| **Diarization** | ‚úÖ Oui (qui parle quand) | ‚ùå Non |
| **Vitesse** | Plus lent | Plus rapide |
| **Pr√©cision** | Meilleure | Bonne |
| **Use case** | Transcription pr√©cise avec speakers | Transcription rapide simple |
| **Queue Redis** | DB 0 | DB 1 |

‚Üí Voir [services/ai/whisperx.md](services/ai/whisperx.md) et [services/ai/faster-whisper-queue.md](services/ai/faster-whisper-queue.md)

---

## üéì Workflow Recommand√© pour un LLM

### Premi√®re Requ√™te de l'Utilisateur

1. **Lire** `LLM_ONBOARDING.md` (ce fichier) - Vue d'ensemble
2. **Lire** `index.md` - √âtat actuel des services
3. **Lire** `SERVER_STATUS.md` et `SERVICES_STATUS.md` - Statut live

### Requ√™te Technique sur un Service

1. **Lire** `services/<categorie>/<service>.md` - Fiche technique
2. **Lire** `guides/services/<categorie>/<service>-*.md` - Guides d√©taill√©s
3. **R√©f√©rence** `reference/docker/commands.md` ou `reference/nginx/` si besoin

### Probl√®me / D√©pannage

1. **Lire** `EMERGENCY_RUNBOOK.md` - Proc√©dures d'urgence
2. **Lire** `guides/infrastructure/nginx-troubleshooting.md`
3. **R√©f√©rence** `changelog/` pour historique r√©cent

### D√©ploiement / Modification

1. **Lire** `guides/deployment/` - Guides de d√©ploiement
2. **R√©f√©rence** `reference/docker/compose-patterns.md` - Templates
3. **Lire** `analysis/` pour comprendre les choix techniques

---

## ‚ö†Ô∏è Pi√®ges Courants √† √âviter

### 1. Ne Pas Confondre Auto-Start et Always-On

**Erreur courante:** "Dashy ne r√©pond pas" ‚Üí Sugg√©rer d'attendre le d√©marrage auto-start
**R√©alit√©:** Dashy est ALWAYS-ON, si √ßa ne r√©pond pas, c'est un vrai probl√®me

**Services Always-On (ne jamais dire "attends le d√©marrage"):**
- Dashy, MkDocs, Grafana, Redis Queue, Nginx, Dozzle, Portainer

**Services Auto-Start (OK de dire "attends 30-180s"):**
- WhisperX, Faster-Whisper, WordPress, Nextcloud, Jitsi, Rocket.Chat, etc.

### 2. Ne Pas Modifier Nginx Sans Tester

**Toujours inclure ces commandes apr√®s modification Nginx:**
```bash
nginx -t                    # Tester la config
systemctl reload nginx      # Recharger si OK
```

### 3. Status Checks de Dashy D√©sactiv√©s

**Contexte:** Dashy avait des status checks qui emp√™chaient l'auto-stop
**Solution:** Status checks SUPPRIM√âS (pas d√©sactiv√©s, SUPPRIM√âS)
**R√©f√©rence:** [changelog/dashy-autostart-fix-2025-10-24.md](changelog/dashy-autostart-fix-2025-10-24.md)

**Ne JAMAIS sugg√©rer de r√©activer les status checks dans Dashy sans mentionner le conflit auto-stop!**

### 4. Redis Queue Partag√© - Ne Pas Red√©marrer √† la L√©g√®re

**Important:** Redis Queue (`rq-queue-redis`) est partag√© par WhisperX ET Faster-Whisper
**Impact d'un restart:** Perte des jobs en cours dans les 2 queues

**Commande safe pour voir les queues:**
```bash
docker exec -it rq-queue-redis redis-cli
SELECT 0  # WhisperX
LLEN transcription
SELECT 1  # Faster-Whisper
LLEN faster-whisper-transcription
```

---

## üìä M√©triques Cl√©s du Serveur

### Ressources

- **RAM Total:** 32GB
- **CPU:** 8 vCPUs
- **Disque:** 400GB SSD
- **Conteneurs actifs:** ~15-25 (varie avec auto-start)
- **Conteneurs total:** ~40

### Limites Connues

- **Max conteneurs simultan√©s:** ~40 (incident Netdata √† 59 conteneurs)
- **RAM critique:** >28GB ‚Üí Risque OOM
- **Auto-stop timeout:** 15 minutes (900s)
- **Auto-start boot time:** 30-180s selon service

---

## üîó Liens Utiles pour le LLM

### Dashboards Live

- **Dashy:** https://dashy.srv759970.hstgr.cloud - Vue d'ensemble tous services
- **Grafana:** https://monitoring.srv759970.hstgr.cloud - M√©triques & logs
- **Dozzle:** https://dozzle.srv759970.hstgr.cloud - Logs Docker temps r√©el

### Documentation Externe

- **Dashy Docs:** https://dashy.to/docs
- **MkDocs Material:** https://squidfunk.github.io/mkdocs-material/
- **Docker Compose:** https://docs.docker.com/compose/
- **Nginx:** https://nginx.org/en/docs/

---

## üÜò En Cas de Doute

**Si tu ne sais pas comment r√©pondre:**

1. Consulter `EMERGENCY_RUNBOOK.md` pour urgences
2. Chercher dans `changelog/` pour historique r√©cent
3. Lire `analysis/` pour comprendre les d√©cisions
4. Proposer de lire les logs: `docker logs <service> --tail 100`
5. Demander √† Julien de v√©rifier `SERVER_STATUS.md` (auto-g√©n√©r√©)

**Principe:** Mieux vaut demander confirmation que donner une mauvaise info sur un serveur de production!

---

## üìù Changelog de ce Guide

- **2025-10-27:** Cr√©ation initiale du guide d'onboarding LLM
- **Prochaine r√©vision:** Apr√®s premier usage r√©el par un LLM

---

**Bienvenue sur srv759970! üöÄ**

*Ce guide est maintenu manuellement. Si tu d√©tectes une incoh√©rence avec les autres docs, signale-le √† Julien.*
