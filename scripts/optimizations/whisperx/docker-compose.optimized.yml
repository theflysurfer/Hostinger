version: '3.8'

services:
  # Redis Queue
  rq-queue-redis:
    image: redis:7-alpine
    container_name: rq-queue-redis
    restart: unless-stopped
    ports:
      - '6380:6379'
    volumes:
      - rq-queue-redis-data:/data
    networks:
      - whisperx
    deploy:
      resources:
        limits:
          memory: 512M
          cpus: '0.5'
    healthcheck:
      test: ['CMD', 'redis-cli', 'ping']
      interval: 5s
      timeout: 3s
      retries: 5
    logging:
      driver: json-file
      options:
        max-size: '10m'
        max-file: '3'

  # WhisperX API Server
  whisperx:
    build:
      context: .
      dockerfile: Dockerfile.optimized
    container_name: whisperx
    restart: unless-stopped
    ports:
      - '8002:8002'
    environment:
      - REDIS_URL=redis://rq-queue-redis:6379
      - HF_TOKEN=${HF_TOKEN}
      - PYTHONUNBUFFERED=1
    volumes:
      # IMPORTANT: Models stored OUTSIDE container (not in image)
      - whisperx-models:/models
      - /tmp/uploads:/tmp/uploads
    depends_on:
      rq-queue-redis:
        condition: service_healthy
    networks:
      - whisperx
    deploy:
      resources:
        limits:
          memory: 4G
          cpus: '2.0'
        reservations:
          memory: 2G
          cpus: '1.0'
    healthcheck:
      test: ['CMD', 'curl', '-f', 'http://localhost:8002/']
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 40s
    logging:
      driver: json-file
      options:
        max-size: '10m'
        max-file: '3'
    labels:
      - "com.centurylinklabs.watchtower.enable=true"

  # WhisperX Worker
  whisperx-worker:
    build:
      context: .
      dockerfile: Dockerfile.optimized
    container_name: whisperx-worker
    restart: unless-stopped
    command: python worker.py
    environment:
      - REDIS_URL=redis://rq-queue-redis:6379
      - HF_TOKEN=${HF_TOKEN}
      - PYTHONUNBUFFERED=1
    volumes:
      # Share same models volume
      - whisperx-models:/models
      - /tmp/uploads:/tmp/uploads
    depends_on:
      - rq-queue-redis
    networks:
      - whisperx
    deploy:
      resources:
        limits:
          memory: 6G
          cpus: '4.0'
        reservations:
          memory: 4G
          cpus: '2.0'
    logging:
      driver: json-file
      options:
        max-size: '10m'
        max-file: '3'
    labels:
      - "com.centurylinklabs.watchtower.enable=true"

  # RQ Dashboard
  rq-dashboard:
    image: eoranged/rq-dashboard:latest
    container_name: whisperx-dashboard
    restart: unless-stopped
    ports:
      - '9181:9181'
    environment:
      - RQ_DASHBOARD_REDIS_URL=redis://rq-queue-redis:6379
    depends_on:
      - rq-queue-redis
    networks:
      - whisperx
    deploy:
      resources:
        limits:
          memory: 256M
    logging:
      driver: json-file
      options:
        max-size: '10m'
        max-file: '3'

volumes:
  rq-queue-redis-data:
    driver: local
  whisperx-models:
    driver: local
    # Models are cached here and persist across container rebuilds
    # First run will download models (~1-2GB)
    # Subsequent runs reuse cached models

networks:
  whisperx:
    driver: bridge
