#!/usr/bin/env python3
"""
Analyse r√©sultats benchmark Whisper

Compare faster-whisper vs WhisperX sur:
- Temps de traitement
- Nombre de tokens
- Efficacit√© par taille de fichier
"""
import json
import pandas as pd
from pathlib import Path
import sys

# ============================================================================
# CONFIGURATION
# ============================================================================

RESULTS_FILE = Path(__file__).parent / "results" / "benchmark_results.json"

# ============================================================================
# CHARGEMENT R√âSULTATS
# ============================================================================

def load_results() -> pd.DataFrame:
    """Charge r√©sultats JSON en DataFrame pandas"""

    if not RESULTS_FILE.exists():
        print(f"‚ùå Fichier r√©sultats introuvable: {RESULTS_FILE}")
        print("üí° Lancez d'abord: python benchmark.py")
        sys.exit(1)

    with open(RESULTS_FILE, encoding="utf-8") as f:
        results = json.load(f)

    if not results:
        print("‚ùå Aucun r√©sultat dans le fichier JSON")
        sys.exit(1)

    df = pd.DataFrame(results)

    # Filtrer erreurs
    errors = df[df["error"].notna()] if "error" in df.columns else pd.DataFrame()

    if not errors.empty:
        print(f"‚ö†Ô∏è  {len(errors)} erreurs d√©tect√©es:")
        for _, row in errors.iterrows():
            print(f"   - {row['audio_file']} ({row['service']}): {row.get('error', 'Unknown')[:100]}")
        print()

    # Garder seulement r√©sultats valides
    df_valid = df[df["error"].isna()] if "error" in df.columns else df

    return df_valid

# ============================================================================
# CAT√âGORISATION
# ============================================================================

def categorize_files(df: pd.DataFrame) -> pd.DataFrame:
    """Ajoute cat√©gories de taille fichier"""

    df = df.copy()

    df["size_category"] = pd.cut(
        df["audio_size_mb"],
        bins=[0, 2, 10, 200],
        labels=["Court (<2MB)", "Moyen (2-10MB)", "Long (>10MB)"]
    )

    return df

# ============================================================================
# ANALYSES
# ============================================================================

def print_header(title: str):
    """Affiche un header stylis√©"""
    print("\n" + "=" * 80)
    print(f"  {title}")
    print("=" * 80 + "\n")

def analyze_processing_time(df: pd.DataFrame):
    """Analyse temps de traitement"""

    print_header("‚è±Ô∏è  TEMPS DE TRAITEMENT")

    # Par service
    time_stats = df.groupby("service")["duration_seconds"].agg([
        ("Moyenne", "mean"),
        ("Min", "min"),
        ("Max", "max"),
        ("Std Dev", "std")
    ]).round(2)

    print("üìä Statistiques par service:\n")
    print(time_stats)

    # Calcul speedup
    if "faster-whisper" in df["service"].values and "whisperx" in df["service"].values:
        fw_mean = df[df["service"] == "faster-whisper"]["duration_seconds"].mean()
        wx_mean = df[df["service"] == "whisperx"]["duration_seconds"].mean()

        speedup = ((wx_mean - fw_mean) / fw_mean) * 100

        print(f"\nüí° WhisperX est {abs(speedup):.1f}% {'plus lent' if speedup > 0 else 'plus rapide'} que faster-whisper")

def analyze_tokens(df: pd.DataFrame):
    """Analyse nombre de tokens"""

    print_header("üî¢ NOMBRE DE TOKENS")

    token_stats = df.groupby("service")["tokens"].agg([
        ("Moyenne", "mean"),
        ("Min", "min"),
        ("Max", "max"),
        ("Total", "sum")
    ]).round(0).astype(int)

    print("üìä Statistiques par service:\n")
    print(token_stats)

    # Tokens par MB
    df_temp = df.copy()
    df_temp["tokens_per_mb"] = df_temp["tokens"] / df_temp["audio_size_mb"]

    tokens_per_mb = df_temp.groupby("service")["tokens_per_mb"].mean().round(0).astype(int)

    print("\nüìè Tokens par MB d'audio:\n")
    print(tokens_per_mb)

def analyze_by_file_size(df: pd.DataFrame):
    """Analyse par taille de fichier"""

    print_header("üìè PERFORMANCE PAR TAILLE DE FICHIER")

    # Temps moyen par cat√©gorie
    time_by_size = df.pivot_table(
        values="duration_seconds",
        index="size_category",
        columns="service",
        aggfunc="mean"
    ).round(2)

    print("‚è±Ô∏è  Temps moyen (secondes) par cat√©gorie:\n")
    print(time_by_size)

    # Tokens par cat√©gorie
    tokens_by_size = df.pivot_table(
        values="tokens",
        index="size_category",
        columns="service",
        aggfunc="mean"
    ).round(0).astype(int)

    print("\nüî¢ Tokens moyens par cat√©gorie:\n")
    print(tokens_by_size)

def analyze_diarization(df: pd.DataFrame):
    """Analyse impact diarization (WhisperX uniquement)"""

    print_header("üé§ IMPACT DIARIZATION (WhisperX)")

    df_wx = df[df["service"] == "whisperx"].copy()

    if df_wx.empty or "diarization" not in df_wx.columns:
        print("‚ö†Ô∏è  Pas de donn√©es WhisperX disponibles")
        return

    # Comparer avec/sans diarization
    diar_stats = df_wx.groupby("diarization").agg({
        "duration_seconds": ["mean", "count"],
        "num_speakers": "mean"
    }).round(2)

    print("üìä Statistiques diarization:\n")
    print(diar_stats)

    # Overhead diarization
    if True in df_wx["diarization"].values and False in df_wx["diarization"].values:
        time_with = df_wx[df_wx["diarization"] == True]["duration_seconds"].mean()
        time_without = df_wx[df_wx["diarization"] == False]["duration_seconds"].mean()

        overhead = ((time_with - time_without) / time_without) * 100

        print(f"\nüí° Overhead diarization: +{overhead:.1f}% de temps de traitement")

    # Speakers d√©tect√©s
    if "num_speakers" in df_wx.columns:
        avg_speakers = df_wx[df_wx["diarization"] == True]["num_speakers"].mean()
        if pd.notna(avg_speakers):
            print(f"üë• Moyenne speakers d√©tect√©s: {avg_speakers:.1f}")

def analyze_efficiency(df: pd.DataFrame):
    """Analyse efficacit√© (secondes de traitement par MB)"""

    print_header("‚ö° EFFICACIT√â (Temps / Taille)")

    df_temp = df.copy()
    df_temp["seconds_per_mb"] = df_temp["duration_seconds"] / df_temp["audio_size_mb"]

    efficiency = df_temp.groupby("service")["seconds_per_mb"].agg([
        ("Moyenne", "mean"),
        ("Min", "min"),
        ("Max", "max")
    ]).round(2)

    print("üìä Secondes de traitement par MB d'audio:\n")
    print(efficiency)

    best_service = efficiency["Moyenne"].idxmin()
    print(f"\nüí° Service le plus efficace: {best_service}")

# ============================================================================
# RECOMMANDATIONS
# ============================================================================

def generate_recommendations(df: pd.DataFrame):
    """G√©n√®re recommandations bas√©es sur r√©sultats"""

    print_header("üí° RECOMMANDATIONS")

    # Service le plus rapide
    fastest = df.groupby("service")["duration_seconds"].mean().idxmin()
    print(f"üèÜ Service le plus rapide: {fastest}")

    # Service avec le plus de tokens (plus verbeux)
    most_tokens = df.groupby("service")["tokens"].mean().idxmax()
    print(f"üìù Service le plus verbeux: {most_tokens}")

    # Meilleure efficacit√©
    df_temp = df.copy()
    df_temp["seconds_per_mb"] = df_temp["duration_seconds"] / df_temp["audio_size_mb"]
    most_efficient = df_temp.groupby("service")["seconds_per_mb"].mean().idxmin()
    print(f"‚ö° Service le plus efficace: {most_efficient}")

    print("\nüìã Cas d'usage recommand√©s:\n")
    print("   faster-whisper:")
    print("   ‚úÖ Transcription simple sans speakers")
    print("   ‚úÖ Performance maximale requise")
    print("   ‚úÖ API compatible OpenAI\n")

    print("   WhisperX:")
    print("   ‚úÖ Identification speakers (meetings, interviews)")
    print("   ‚úÖ Timestamps pr√©cis (¬±50ms)")
    print("   ‚úÖ Audio multi-locuteurs")

# ============================================================================
# EXPORT
# ============================================================================

def export_csv(df: pd.DataFrame):
    """Exporte r√©sultats en CSV"""

    output_file = Path(__file__).parent / "results" / "benchmark_analysis.csv"

    # Supprimer colonne texte (trop longue)
    df_export = df.drop(columns=["text"], errors="ignore")

    df_export.to_csv(output_file, index=False, encoding="utf-8")

    print(f"\nüíæ Analyse export√©e: {output_file}")

# ============================================================================
# MAIN
# ============================================================================

def main():
    """Fonction principale"""

    print("=" * 80)
    print("  üìä ANALYSE BENCHMARK WHISPER")
    print("=" * 80)

    # Charger r√©sultats
    df = load_results()

    print(f"\n‚úÖ {len(df)} r√©sultats charg√©s")

    # Cat√©goriser
    df = categorize_files(df)

    # Analyses
    analyze_processing_time(df)
    analyze_tokens(df)
    analyze_by_file_size(df)
    analyze_diarization(df)
    analyze_efficiency(df)

    # Recommandations
    generate_recommendations(df)

    # Export
    export_csv(df)

    print("\n" + "=" * 80)
    print("  ‚úÖ ANALYSE TERMIN√âE")
    print("=" * 80 + "\n")

if __name__ == "__main__":
    main()
